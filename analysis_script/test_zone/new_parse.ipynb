{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitca55d86ee1334d17b3386655debf1df5",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: David Ho\n",
    "Institute: National Tsing Hua university, Department of Physics, Hsinchu, Taiwan \n",
    "Mail: davidho@gapp.nthu.edu.tw\n",
    "\"\"\"\n",
    "#Import packages\n",
    "import uproot\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from script.particle import particle_properties  #import particle properties helper function from particle_properties.py\n",
    "from script.jet import jet_properties  #import jet properties helper function from jet_properties.py\n",
    "from script.MissingET import Missing_ET_properties\n",
    "from script.electron import electron_properties\n",
    "from script.muon import muon_properties\n",
    "\n",
    "import h5py, sys, traceback, os, tqdm, time\n",
    "from script.utilize import delta_R, deltaPhi, pdgid, event_selection, quark_finder, particle_tracing, deltaR_matching, barcode_recorder, deltaPhi\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------------------------------------------------------------------------------------------------------+\n",
      "Start loading dataset.\n",
      "+------------------------------------------------------------------------------------------------------+\n",
      "Loading particle information.\n",
      "Loading jet information.\n",
      "Loading electron information.\n",
      "Loading muon information.\n",
      "Loading MissingET information.\n",
      "  1%|▏         | 1289/100000 [00:00<00:07, 12889.67it/s]+------------------------------------------------------------------------------------------------------+\n",
      "Dataset loaded.\n",
      "+------------------------------------------------------------------------------------------------------+\n",
      "+------------------------------------------------------------------------------------------------------+\n",
      "Start jet selection.\n",
      "+------------------------------------------------------------------------------------------------------+\n",
      "Start jet marking.\n",
      "100%|██████████| 100000/100000 [00:07<00:00, 12625.94it/s]\n",
      "100%|██████████| 100000/100000 [00:01<00:00, 82361.62it/s]\n",
      " 20%|█▉        | 19541/100000 [00:00<00:00, 98153.33it/s]Start event marking.\n",
      "100%|██████████| 100000/100000 [00:00<00:00, 102470.87it/s]\n",
      " 58%|█████▊    | 6742/11624 [00:00<00:00, 67411.06it/s]+------------------------------------------------------------------------------------------------------+\n",
      "Jet selection done. 11624 events has been selected.\n",
      "+------------------------------------------------------------------------------------------------------+\n",
      "+------------------------------------------------------------------------------------------------------+\n",
      "Recording the kinematics variables of jets in the selected event.\n",
      "+------------------------------------------------------------------------------------------------------+\n",
      "100%|██████████| 11624/11624 [00:00<00:00, 67134.28it/s]\n",
      "100%|██████████| 11624/11624 [00:01<00:00, 7231.44it/s]+------------------------------------------------------------------------------------------------------+\n",
      "Finished to record the kinematics variables of jets in the selected event.\n",
      "+------------------------------------------------------------------------------------------------------+\n",
      "+------------------------------------------------------------------------------------------------------+\n",
      "Starting parton tracing and looking for its daughter.\n",
      "+------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-df63ded6bc4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframelize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPID\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTATUS_CODE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODEL\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODLE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSINGLE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPROCESS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGENERATOR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-df63ded6bc4e>\u001b[0m in \u001b[0;36mparse\u001b[0;34m(INPUT_FILE, OUTPUT_FILE, MODEL, SINGLE, PROCESS, GENERATOR)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mMODEL\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ttbar'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mMODEL\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ttbar_lep_left'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mMODEL\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;34m'ttbar_lep_right'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframelize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPID\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTATUS_CODE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODEL\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODLE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSINGLE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPROCESS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGENERATOR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all input arrays must have the same shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0mresult_ndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all input arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "INPUT_FILE = \"../data/ttbar_lep_data/left/tag_1_delphes_events.root\"\n",
    "# INPUT_FILE = \"../data/ttbar_data/tag_1_delphes_events_1.root\"\n",
    "\n",
    "OUTPUT_FILE = \"\"\n",
    "SINGLE = True\n",
    "PROCESS = 48\n",
    "GENERATOR = 'py8'\n",
    "MODLE = 'ttbar_lep_left'\n",
    "# MODLE = 'ttbar'\n",
    "\n",
    "def parse(INPUT_FILE, OUTPUT_FILE, MODEL, SINGLE, PROCESS, GENERATOR):\n",
    "    PID = pdgid()\n",
    "    # Setting `STATUS_CODE` for different shower generator.\n",
    "    if GENERATOR == 'py8':\n",
    "        STATUS_CODE = 22\n",
    "    elif GENERATOR == 'herwig7':\n",
    "        STATUS_CODE = 11\n",
    "    else: \n",
    "        print(\"Please select a correct shower generator. 1. py8, 2. herwig7.\")\n",
    "\n",
    "    MAX_NUM_OF_JETS = 20\n",
    "\n",
    "    # Setting barcode, `NUM_OF_PARTON`, and `NUM_OF_DAUGHTER` for different model\n",
    "    if MODEL == \"ttbar\":\n",
    "        \"\"\"\n",
    "        Barcode system\n",
    "        t t~ W+ W- b b~ \n",
    "        0 0  0  0  0 0\n",
    "        daughter of top and W+: 101000 ----> 40\n",
    "        daughter of top and b: 101000 ----> 34\n",
    "        daughter of anti top and W-: 100100 ----> 20\n",
    "        daughter of anti top and b~: 100001 ----> 17\n",
    "        \"\"\"\n",
    "        barcode = np.array([34, 40, 40, 17, 20, 20])\n",
    "        NUM_OF_PARTON = 6\n",
    "        NUM_OF_DAUGHTER = 6\n",
    "    elif MODEL == \"ttbar_lep_left\":\n",
    "        \"\"\"\n",
    "        Barcode system\n",
    "        t t~ W+ W- b b~ \n",
    "        0 0  0  0  0 0\n",
    "        daughter of top and W+: 101000 ----> 40\n",
    "        daughter of top and b: 101000 ----> 34\n",
    "        daughter of anti top and W-: 100100 ----> 20\n",
    "        daughter of anti top and b~: 100001 ----> 17\n",
    "        \"\"\"\n",
    "        barcode = np.array([34, 40, 40, 17, 20, 20])\n",
    "        NUM_OF_PARTON = 4\n",
    "        NUM_OF_DAUGHTER = 6\n",
    "    elif MODEL == \"ttbar_lep_right\":\n",
    "        \"\"\"\n",
    "        Barcode system\n",
    "        t t~ W+ W- b b~ \n",
    "        0 0  0  0  0 0\n",
    "        daughter of top and W+: 101000 ----> 40\n",
    "        daughter of top and b: 101000 ----> 34\n",
    "        daughter of anti top and W-: 100100 ----> 20\n",
    "        daughter of anti top and b~: 100001 ----> 17\n",
    "        \"\"\"\n",
    "        barcode = np.array([34, 40, 40, 17, 20, 20])\n",
    "        NUM_OF_PARTON = 4\n",
    "        NUM_OF_DAUGHTER = 6\n",
    "    elif MODEL == \"ttH\":\n",
    "        \"\"\"\n",
    "        Barcode system\n",
    "        t t~ W+ W- b b~ H\n",
    "        0 0  0  0  0 0  0\n",
    "        daughter of t and b = 1000100  ----> 68\n",
    "        daughter of t and W+ = 1010000 ----> 80\n",
    "        daughter of t~ and W- = 0101000 ----> 34\n",
    "        daughter of t~ and b~ = 0100010 ----> 40\n",
    "        daughter of H = 0000001 ----> 1\n",
    "        \"\"\"\n",
    "        barcode = np.array([68, 80, 80, 34, 40, 40, 1, 1])\n",
    "        NUM_OF_PARTON = 8\n",
    "        NUM_OF_DAUGHTER = 8\n",
    "    elif MODEL == \"four_top\":\n",
    "        \"\"\"\n",
    "        Barcode system\n",
    "        t1 t2 t1~ t2~ W+1 W-1 W+2 W-2 b1 b2 b1~ b2~             describe          barcode   sequence\n",
    "        0  0   0   0   0   0   0   0  0  0   0   0\n",
    "\n",
    "        1  0   0   0   1   0   0   0  0  0   0   0  <--- daughter of t1 and W+1   2176         2,3\n",
    "        1  0   0   0   0   0   0   0  1  0   0   0  <--- daughter of t1 and b1    2056          1\n",
    "        0  0   1   0   0   1   0   0  0  0   0   0  <--- daughter of t1~ and W-1  576          5,6\n",
    "        0  0   1   0   0   0   0   0  0  1   0   0  <--- daughter of t1~ and b1~  516           4\n",
    "\n",
    "        0  1   0   0   0   0   1   0  0  0   0   0  <--- daughter of t2 and W+2   1056         7,8\n",
    "        0  1   0   0   0   0   0   0  0  1   0   0  <--- daughter of t2 and b2    1028          9\n",
    "        0  0   0   1   0   0   0   1  0  0   0   0  <--- daughter of t2~ and W-2  272          11.12\n",
    "        0  0   0   1   0   0   0   0  0  0   0   1  <--- daughter of t2~ and b2~  257           10\n",
    "\n",
    "        \"\"\"\n",
    "        barcode = np.array([2056, 2176, 2176, 516, 576, 576, 1028, 1056, 1056, 257, 272, 272])\n",
    "        NUM_OF_PARTON = 12\n",
    "        NUM_OF_DAUGHTER = 12\n",
    "    else:\n",
    "        print(\"Please select a correct model.\")\n",
    "\n",
    "    print(\"+------------------------------------------------------------------------------------------------------+\")\n",
    "    print(\"Start loading dataset.\")\n",
    "    print(\"+------------------------------------------------------------------------------------------------------+\")\n",
    "    if SINGLE:\n",
    "        data = uproot.open(INPUT_FILE)['Delphes']\n",
    "        particle = particle_properties(data)\n",
    "        jet = jet_properties(data)\n",
    "        if MODEL == 'ttbar_lep_left' or MODEL == \"ttbar_lep_right\":\n",
    "            electron = electron_properties(data)\n",
    "            muon = muon_properties(data)\n",
    "            missing_et = Missing_ET_properties(data)\n",
    "    else: \n",
    "        files = os.listdir(INPUT_FILE)\n",
    "        PATH = []\n",
    "        for a in files:\n",
    "            PATH.append(os.path.join(INPUT_FILE, a))\n",
    "        particle = particle_properties(PATH, single=False)\n",
    "        jet = jet_properties(PATH, single=False)\n",
    "        if MODEL == 'ttbar_lep_left' or MODEL == \"ttbar_lep_right\":\n",
    "            electron = electron_properties(PATH, single=False)\n",
    "            muon = muon_properties(PATH, single=False)\n",
    "            missing_et = Missing_ET_properties(PATH, single=False)\n",
    "    print(\"+------------------------------------------------------------------------------------------------------+\")\n",
    "    print(\"Dataset loaded.\")\n",
    "    print(\"+------------------------------------------------------------------------------------------------------+\")\n",
    "\n",
    "    print(\"+------------------------------------------------------------------------------------------------------+\")\n",
    "    print(\"Start jet selection.\")\n",
    "    print(\"+------------------------------------------------------------------------------------------------------+\")\n",
    "    if MODEL == 'ttbar':\n",
    "        # Find the event that exists at least 2 b-jet passed the selection\n",
    "        btag_passed = np.where(((jet.btag == 1) & (jet.pt >= 25) & (np.abs(jet.eta) < 2.5) ).sum() >= 2)\n",
    "        # Find the event that exists at least 6 non b-jet passed the selection\n",
    "        non_btag_passed = np.where(((jet.pt >= 25) & (np.abs(jet.eta) < 2.5) ).sum() >= 6)\n",
    "        # Combine the result above \n",
    "        passed = np.intersect1d(btag_passed[0], non_btag_passed[0])\n",
    "    elif MODEL == 'four_top':\n",
    "        # Find the event that exists at least 2 b-jet passed the selection\n",
    "        btag_passed = np.where(((jet.btag == 1) & (jet.pt >= 25) & (np.abs(jet.eta) < 2.5) ).sum() >= 2)\n",
    "        # Find the event that exists at least 12 non b-jet passed the selection\n",
    "        non_btag_passed = np.where(((jet.pt >= 25) & (np.abs(jet.eta) < 2.5) ).sum() >= 12)\n",
    "        # Combine the result above \n",
    "        passed = np.intersect1d(btag_passed[0], non_btag_passed[0])\n",
    "    elif MODEL == 'ttH':\n",
    "        # Find the event that exists at least 2 b-jet passed the selection\n",
    "        btag_passed = np.where(((jet.btag == 1) & (jet.pt >= 25) & (np.abs(jet.eta) < 2.5) ).sum() >= 2)\n",
    "        # Find the event that exists at least 8 non b-jet passed the selection\n",
    "        non_btag_passed = np.where(((jet.pt >= 25) & (np.abs(jet.eta) < 2.5) ).sum() >= 8)\n",
    "        # Combine the result above \n",
    "        passed = np.intersect1d(btag_passed[0], non_btag_passed[0])\n",
    "    elif MODEL == 'ttbar_lep_left' or MODEL == \"ttbar_lep_right\":\n",
    "        marker_lepton = []\n",
    "        marker_event = []\n",
    "        marker_jet = []\n",
    "        marker_btag = []\n",
    "        print(\"Start jet marking.\")\n",
    "        for i in tqdm.trange(len(jet.pt)):\n",
    "            _marker_event = []\n",
    "            _marker_jet = []\n",
    "            _marker_btag = []\n",
    "            for j in range(len(jet.pt[i])):\n",
    "                if jet.btag[i][j] == 1 and jet.pt[i][j] > 25 and np.abs(jet.eta[i][j]) < 2.5:\n",
    "                    _marker_btag.append(1) \n",
    "                else: \n",
    "                    _marker_btag.append(0) \n",
    "            \n",
    "                if jet.pt[i][j] > 25 and np.abs(jet.eta[i][j]) <= 2.5:\n",
    "                    _marker_jet.append(1)\n",
    "                else:\n",
    "                    _marker_jet.append(0)\n",
    "            marker_jet.append(np.asanyarray(_marker_jet, dtype=object))\n",
    "            marker_btag.append(np.asanyarray(_marker_btag, dtype=object))\n",
    "        \n",
    "        marker_jet = np.asanyarray(marker_jet, dtype=object)\n",
    "        marker_btag = np.asanyarray(marker_btag, dtype=object)\n",
    "        \n",
    "        #Remove electron from jets catogary\n",
    "        for i in range(len(jet.pt)):\n",
    "            \n",
    "            for j in range(len(jet.pt[i])):\n",
    "                for k in range(len(electron.pt[i])):\n",
    "                    if delta_R(jet.eta[i][j], jet.phi[i][j], electron.eta[i][k], electron.phi[i][k]) < 0.4:\n",
    "                        marker_jet[i][j] = 0\n",
    "                    else : pass \n",
    "        \n",
    "        for i in tqdm.trange(len(electron.eta)):\n",
    "            _marker_lepton = []\n",
    "            for j in range(len(electron.eta[i])):\n",
    "                if electron.pt[i][j] > 25 and np.abs(electron.eta[i][j]) < 2.5:\n",
    "                    _marker_lepton.append(1)\n",
    "                else :\n",
    "                    _marker_lepton.append(0)\n",
    "            for j in range(len(muon.eta[i])):\n",
    "                if muon.pt[i][j] > 25 and np.abs(muon.eta[i][j]) < 2.5:\n",
    "                    _marker_lepton.append(1)\n",
    "                else :\n",
    "                    _marker_lepton.append(0)\n",
    "            marker_lepton.append(np.asanyarray(_marker_lepton, dtype=object))\n",
    "        marker_lepton = np.asanyarray(marker_lepton, dtype=object)\n",
    "        print(\"Start event marking.\")\n",
    "        for i in tqdm.trange(len(jet.pt)):\n",
    "            if np.sum(marker_jet[i] == 1) >= 4 and np.sum(marker_btag[i] == 1) >= 2 and np.sum(marker_lepton[i] ==1) == 1 and len(marker_lepton[i]) == 1:\n",
    "                marker_event.append(1)\n",
    "            else:\n",
    "                marker_event.append(0)\n",
    "        marker_event = np.asanyarray(marker_event, dtype=object)\n",
    "        passed = np.where(marker_event == 1)[0]\n",
    "        del marker_jet, marker_btag, marker_lepton, marker_event\n",
    "    print(\"+------------------------------------------------------------------------------------------------------+\")\n",
    "    print(\"Jet selection done. {0} events has been selected.\".format(len(passed)))\n",
    "    print(\"+------------------------------------------------------------------------------------------------------+\")\n",
    "\n",
    "    print(\"+------------------------------------------------------------------------------------------------------+\")\n",
    "    print(\"Recording the kinematics variables of jets in the selected event.\")\n",
    "    print(\"+------------------------------------------------------------------------------------------------------+\")\n",
    "    if MODEL == 'ttbar_lep_left' or MODEL == \"ttbar_lep_right\":\n",
    "        # Initialize the numpy.ndarray for jet, leptons, and MET\n",
    "        jet_pt = np.zeros((len(passed), MAX_NUM_OF_JETS))\n",
    "        jet_eta = np.zeros((len(passed), MAX_NUM_OF_JETS))\n",
    "        jet_phi = np.zeros((len(passed), MAX_NUM_OF_JETS))\n",
    "        jet_mass = np.zeros((len(passed), MAX_NUM_OF_JETS))\n",
    "        jet_btag = np.zeros((len(passed), MAX_NUM_OF_JETS))\n",
    "        jet_num_of_jets = np.zeros((len(passed), MAX_NUM_OF_JETS))\n",
    "        \n",
    "        # Since we require only 1 lepton can exists in each event, so we don't need second dimension.\n",
    "        lepton_pt = np.zeros((len(passed)))\n",
    "        lepton_eta = np.zeros((len(passed)))\n",
    "        lepton_phi = np.zeros((len(passed)))\n",
    "        \n",
    "        # Since the stucture of MET only have 1 element in each event, so we don't need second dimension.\n",
    "        MET = np.zeros((len(passed)))\n",
    "        MET_ETA = np.zeros((len(passed)))\n",
    "        MET_PHI = np.zeros((len(passed)))\n",
    "\n",
    "        # Storing MissingET data\n",
    "        for i in range(len(passed)):\n",
    "            idx = int(passed[i])\n",
    "            MET[i] = missing_et.MET[idx]\n",
    "            MET_ETA[i] = missing_et.eta[idx]\n",
    "            MET_PHI[i] = missing_et.phi[idx]\n",
    "\n",
    "        # Storing lepton data\n",
    "        for i in tqdm.trange(len(passed)):\n",
    "            idx = int(passed[i])\n",
    "            if len(electron.pt[idx]) != 0 and len(muon.pt[idx]) == 0:\n",
    "                lepton_pt[i] = electron.pt[idx][0]\n",
    "                lepton_eta[i] = electron.eta[idx][0]\n",
    "                lepton_phi[i] = electron.phi[idx][0]\n",
    "            elif len(electron.pt[idx]) == 0 and len(muon.pt[idx]) != 0: \n",
    "                lepton_pt[i] = muon.pt[idx][0]\n",
    "                lepton_eta[i] = muon.eta[idx][0]\n",
    "                lepton_phi[i] = muon.phi[idx][0]\n",
    "            else: \n",
    "                print(f\"There exist more than 1 leptons in event {idx}, please check your selection.\")\n",
    "\n",
    "        # Storing jet data with lepton-jet removal (cut: deltaR(jet, lepton) > 0.4)\n",
    "        for i in tqdm.trange(len(passed)):\n",
    "            idx = int(passed[i])\n",
    "            for j in range(len(jet.pt[idx])):\n",
    "                if delta_R(jet.eta[idx][j], jet.phi[idx][j], lepton_eta[i], lepton_phi[i]) > 0.4: \n",
    "                    jet_pt[i][j] = jet.pt[idx][j]\n",
    "                    jet_eta[i][j] = jet.eta[idx][j]\n",
    "                    jet_phi[i][j] = jet.phi[idx][j]\n",
    "                    jet_mass[i][j] = jet.mass[idx][j]\n",
    "                    jet_btag[i][j] = jet.btag[idx][j]\n",
    "                else: \n",
    "                    jet_pt[i][j] = -100\n",
    "                    jet_eta[i][j] = -100\n",
    "                    jet_phi[i][j] = -100\n",
    "                    jet_mass[i][j] = -100\n",
    "                    jet_btag[i][j] = -100\n",
    "            jet_num_of_jets[i] = jet.num_of_jets[idx]\n",
    "            \n",
    "    else:\n",
    "        # Initialize the numpy.ndarray for jet\n",
    "        jet_pt = np.zeros((len(passed), MAX_NUM_OF_JETS))\n",
    "        jet_eta = np.zeros((len(passed), MAX_NUM_OF_JETS))\n",
    "        jet_phi = np.zeros((len(passed), MAX_NUM_OF_JETS))\n",
    "        jet_mass = np.zeros((len(passed), MAX_NUM_OF_JETS))\n",
    "        jet_btag = np.zeros((len(passed), MAX_NUM_OF_JETS))\n",
    "        jet_num_of_jets = np.zeros((len(passed), MAX_NUM_OF_JETS))\n",
    "\n",
    "        # Storing jet data\n",
    "        for i in tqdm.trange(len(passed)):\n",
    "            idx = int(passed[i])\n",
    "            for j in range(len(jet.pt[idx])):\n",
    "                jet_pt[i][j] = jet.pt[idx][j]\n",
    "                jet_eta[i][j] = jet.eta[idx][j]\n",
    "                jet_phi[i][j] = jet.phi[idx][j]\n",
    "                jet_mass[i][j] = jet.mass[idx][j]\n",
    "                jet_btag[i][j] = jet.btag[idx][j]\n",
    "            jet_num_of_jets[i] = jet.num_of_jets[idx]\n",
    "    print(\"+------------------------------------------------------------------------------------------------------+\")\n",
    "    print(\"Finished to record the kinematics variables of jets in the selected event.\")\n",
    "    print(\"+------------------------------------------------------------------------------------------------------+\")\n",
    "\n",
    "    print(\"+------------------------------------------------------------------------------------------------------+\")\n",
    "    print(\"Starting parton tracing and looking for its daughter.\")\n",
    "    print(\"+------------------------------------------------------------------------------------------------------+\")\n",
    "    #Particle tracing and daughter finding section\n",
    "    start = time.time()\n",
    "    if MODEL == 'ttbar' or MODEL == 'ttbar_lep_left' or MODEL =='ttbar_lep_right':\n",
    "        top_idx, top_daughter_idx_1, top_daughter_pid_1, top_daughter_idx_2, top_daughter_pid_2 = [], [], [], [], []\n",
    "        top_bar_idx, top_bar_daughter_idx_1, top_bar_daughter_pid_1, top_bar_daughter_idx_2, top_bar_daughter_pid_2 = [], [], [], [], []\n",
    "        _src_top, _src_anti_top, _index  = [], [], []\n",
    "        for i in range(len(particle.event)):\n",
    "            if marker_event[i] == 1:\n",
    "                _index.append(i)\n",
    "                _src_top.append([particle.dataframelize(i), PID.top, STATUS_CODE, MODEL])\n",
    "                _src_anti_top.append([particle.dataframelize(i), PID.anti_top, STATUS_CODE, MODEL])\n",
    "        print(\"Using {0} process for accelerating speed.\".format(PROCESS))\n",
    "        with mp.Pool(PROCESS) as p:\n",
    "            _result_top = p.starmap(particle_tracing, _src_top)\n",
    "            p.close()\n",
    "            p.join()\n",
    "        print(\"Top tracing finished.\")\n",
    "        with mp.Pool(PROCESS) as p:\n",
    "            _result_anti_top = p.starmap(particle_tracing, _src_anti_top)\n",
    "            p.close()\n",
    "            p.join()\n",
    "        print(\"Anti-Top tracing finished.\")\n",
    "\n",
    "        del _src_top, _src_anti_top\n",
    "\n",
    "        for i in range(len(_result_top)):\n",
    "            top_idx.append(_result_top[i][0])\n",
    "            top_daughter_idx_1.append(_result_top[i][1])\n",
    "            top_daughter_pid_1.append(_result_top[i][2])\n",
    "            top_daughter_idx_2.append(_result_top[i][3])\n",
    "            top_daughter_pid_2.append(_result_top[i][4])\n",
    "            top_bar_idx.append(_result_anti_top[i][0])\n",
    "            top_bar_daughter_idx_1.append(_result_anti_top[i][1])\n",
    "            top_bar_daughter_pid_1.append(_result_anti_top[i][2])\n",
    "            top_bar_daughter_idx_2.append(_result_anti_top[i][3])\n",
    "            top_bar_daughter_pid_2.append(_result_anti_top[i][4])\n",
    "\n",
    "        _src_top_d, _src_anti_top_d = [], []\n",
    "        parton_array = np.zeros([ len(_index) , NUM_OF_DAUGHTER])\n",
    "\n",
    "        for i in range(len(_index)):\n",
    "            j = _index[i]\n",
    "            _src_top_d.append([particle.dataframelize(j), top_daughter_idx_1[i], top_daughter_idx_2[i]])\n",
    "            _src_anti_top_d.append([particle.dataframelize(j), top_bar_daughter_idx_1[i], top_bar_daughter_idx_2[i]])\n",
    "        with mp.Pool(PROCESS) as p:\n",
    "            _result_top = p.starmap(quark_finder, _src_top_d)\n",
    "            p.close()\n",
    "            p.join()\n",
    "        print(\"Daughter of Top's daughter found.\")\n",
    "        with mp.Pool(PROCESS) as p:\n",
    "            _result_anti_top = p.starmap(quark_finder, _src_anti_top_d)\n",
    "            p.close()\n",
    "            p.join()\n",
    "        print(\"Daughter of Anti-Top's daughter found.\")\n",
    "        \n",
    "        del _src_anti_top\n",
    "        for i in range(len(_index)):\n",
    "            parton_array[i][0], parton_array[i][1], parton_array[i][2] = _result_top[i][0], _result_top[i][1], _result_top[i][2]\n",
    "            parton_array[i][3], parton_array[i][4], parton_array[i][5] = _result_anti_top[i][0], _result_anti_top[i][1], _result_anti_top[i][2]\n",
    "        print(\"+------------------------------------------------------------------------------------------------------+\")\n",
    "        print(\"Parton tracing section complete. The daughter of W+/W- and bbbar has been found. Cost: {0:.1f} s\".format(time.time()-start))\n",
    "        print(\"+------------------------------------------------------------------------------------------------------+\")\n",
    "\n",
    "    elif MODEL == 'ttH':\n",
    "        top_idx, top_daughter_idx_1, top_daughter_pid_1, top_daughter_idx_2, top_daughter_pid_2 = [], [], [], [], []\n",
    "        top_bar_idx, top_bar_daughter_idx_1, top_bar_daughter_pid_1, top_bar_daughter_idx_2, top_bar_daughter_pid_2 = [], [], [], [], []\n",
    "        higgs_idx, higgs_daughter_idx_1, higgs_daughter_pid_1, higgs_daughter_idx_2, higgs_daughter_pid_2 = [], [], [], [], []\n",
    "        _src_top, _src_anti_top, _src_higgs, _index  = [], [], [], []\n",
    "        \n",
    "        for i in range(len(particle.event)):\n",
    "            if marker_event[i] == 1:\n",
    "                _index.append(i)\n",
    "                _src_top.append([particle.dataframelize(i), PID.top, STATUS_CODE, MODEL])\n",
    "                _src_anti_top.append([particle.dataframelize(i), PID.anti_top, STATUS_CODE, MODEL])\n",
    "                _src_higgs.append([particle.dataframelize(i), PID.higgs, STATUS_CODE, MODEL])\n",
    "        print(\"Using {0} process for accelerating speed.\".format(PROCESS))\n",
    "        with mp.Pool(PROCESS) as p:\n",
    "            _result_top = p.starmap(particle_tracing, _src_top)\n",
    "            p.close()\n",
    "            p.join()\n",
    "        print(\"Top tracing finished.\")\n",
    "        with mp.Pool(PROCESS) as p:\n",
    "            _result_anti_top = p.starmap(particle_tracing, _src_anti_top)\n",
    "            p.close()\n",
    "            p.join()\n",
    "        print(\"Anti-Top tracing finished.\")\n",
    "        with mp.Pool(PROCESS) as p:\n",
    "            _result_h = p.starmap(particle_tracing, _src_higgs)\n",
    "            p.close()\n",
    "            p.join()\n",
    "        print(\"Higgs tracing finished.\")\n",
    "        \n",
    "        for i in range(len(_index)):\n",
    "            top_idx.append(_result_top[i][0])\n",
    "            top_daughter_idx_1.append(_result_top[i][1])\n",
    "            top_daughter_pid_1.append(_result_top[i][2])\n",
    "            top_daughter_idx_2.append(_result_top[i][3])\n",
    "            top_daughter_pid_2.append(_result_top[i][4])\n",
    "            top_bar_idx.append(_result_anti_top[i][0])\n",
    "            top_bar_daughter_idx_1.append(_result_anti_top[i][1])\n",
    "            top_bar_daughter_pid_1.append(_result_anti_top[i][2])\n",
    "            top_bar_daughter_idx_2.append(_result_anti_top[i][3])\n",
    "            top_bar_daughter_pid_2.append(_result_anti_top[i][4])\n",
    "            higgs_idx.append(_result_h[i][0])\n",
    "            higgs_daughter_idx_1.append(_result_h[i][1])\n",
    "            higgs_daughter_pid_1.append(_result_h[i][2])\n",
    "            higgs_daughter_idx_2.append(_result_h[i][3])\n",
    "            higgs_daughter_pid_2.append(_result_h[i][4])\n",
    "        \n",
    "        _src_top_d, _src_anti_top_d  = [], []\n",
    "        parton_array = np.zeros([ len(_index) , NUM_OF_DAUGHTER])\n",
    "\n",
    "        for i in range(len(_index)):\n",
    "            j = _index[i]\n",
    "            _src_top_d.append([particle.dataframelize(j), top_daughter_idx_1[i], top_daughter_idx_2[i]])\n",
    "            _src_anti_top_d.append([particle.dataframelize(j), top_bar_daughter_idx_1[i], top_bar_daughter_idx_2[i]])\n",
    "        with mp.Pool(PROCESS) as p:\n",
    "            _result_top = p.starmap(quark_finder, _src_top_d)\n",
    "            p.close()\n",
    "            p.join()\n",
    "        print(\"Daughter of Top's daughter found.\")\n",
    "        with mp.Pool(PROCESS) as p:\n",
    "            _result_anti_top = p.starmap(quark_finder, _src_anti_top_d)\n",
    "            p.close()\n",
    "            p.join()\n",
    "        print(\"Daughter of Anti-Top's daughter found.\")\n",
    "        for i in range(len(_index)):\n",
    "            parton_array[i][0], parton_array[i][1], parton_array[i][2] = _result_top[i][0], _result_top[i][1], _result_top[i][2]\n",
    "            parton_array[i][3], parton_array[i][4], parton_array[i][5] = _result_anti_top[i][0], _result_anti_top[i][1], _result_anti_top[i][2]\n",
    "            parton_array[i][6], parton_array[i][7] = higgs_daughter_idx_1[i], higgs_daughter_idx_2[i]\n",
    "        print(\"+------------------------------------------------------------------------------------------------------+\")\n",
    "        print(\"Parton tracing section complete. The daughter of W+/W-, bbbar, and Higgs has been found. Cost: {0:.1f} s\".format(time.time()-start))\n",
    "        print(\"+------------------------------------------------------------------------------------------------------+\")\n",
    "    elif MODEL == 'four_top':\n",
    "        top_1_idx, top_1_daughter_idx_1, top_1_daughter_pid_1, top_1_daughter_idx_2, top_1_daughter_pid_2 = [], [], [], [], []\n",
    "        top_2_idx, top_2_daughter_idx_1, top_2_daughter_pid_1, top_2_daughter_idx_2, top_2_daughter_pid_2 = [], [], [], [], []\n",
    "        top_1_bar_idx, top_1_bar_daughter_idx_1, top_1_bar_daughter_pid_1, top_1_bar_daughter_idx_2, top_1_bar_daughter_pid_2 = [], [], [], [], []\n",
    "        top_2_bar_idx, top_2_bar_daughter_idx_1, top_2_bar_daughter_pid_1, top_2_bar_daughter_idx_2, top_2_bar_daughter_pid_2 = [], [], [], [], []\n",
    "        \n",
    "        _src_top, _src_anti_top, _index  = [], [], []\n",
    "        for i in range(len(particle.event)):\n",
    "            if marker_event[i] == 1:\n",
    "                _index.append(i)\n",
    "                _src_top.append([particle.dataframelize(i), PID.top, STATUS_CODE, MODEL])\n",
    "                _src_anti_top.append([particle.dataframelize(i), PID.anti_top, STATUS_CODE, MODEL])\n",
    "        print(\"Using {0} process for accelerating speed.\".format(PROCESS))\n",
    "        with mp.Pool(PROCESS) as p:\n",
    "            _result_top = p.starmap(particle_tracing, _src_top)\n",
    "            p.close()\n",
    "            p.join()\n",
    "        print(\"Top tracing finished.\")\n",
    "        with mp.Pool(PROCESS) as p:\n",
    "            _result_anti_top = p.starmap(particle_tracing, _src_anti_top)\n",
    "            p.close()\n",
    "            p.join()\n",
    "        print(\"Anti-Top tracing finished.\")\n",
    "        for i in range(len(_index)):\n",
    "            top_1_idx.append(_result_top[i][0])\n",
    "            top_2_idx.append(_result_top[i][1])\n",
    "            top_1_daughter_idx_1.append(_result_top[i][2])\n",
    "            top_1_daughter_pid_1.append(_result_top[i][3]) \n",
    "            top_1_daughter_idx_2.append(_result_top[i][4])\n",
    "            top_1_daughter_pid_2.append(_result_top[i][5])\n",
    "            top_2_daughter_idx_1.append(_result_top[i][6]) \n",
    "            top_2_daughter_pid_1.append(_result_top[i][7])\n",
    "            top_2_daughter_idx_2.append(_result_top[i][8])\n",
    "            top_2_daughter_pid_2.append(_result_top[i][9])\n",
    "            top_1_bar_idx.append(_result_anti_top[i][0])\n",
    "            top_2_bar_idx.append(_result_anti_top[i][1])\n",
    "            top_1_bar_daughter_idx_1.append(_result_anti_top[i][2]) \n",
    "            top_1_bar_daughter_pid_1.append(_result_anti_top[i][3])\n",
    "            top_1_bar_daughter_idx_2.append(_result_anti_top[i][4])\n",
    "            top_1_bar_daughter_pid_2.append(_result_anti_top[i][5])\n",
    "            top_2_bar_daughter_idx_1.append(_result_anti_top[i][6]) \n",
    "            top_2_bar_daughter_pid_1.append(_result_anti_top[i][7])\n",
    "            top_2_bar_daughter_idx_2.append(_result_anti_top[i][8])\n",
    "            top_2_bar_daughter_pid_2.append(_result_anti_top[i][9])\n",
    "        \n",
    "        _src_top_d_1, _src_top_d_2, _src_anti_top_d_1, _src_anti_top_d_2 = [], [], [], []\n",
    "        \n",
    "        parton_array = np.zeros([ len(_index) , NUM_OF_DAUGHTER])\n",
    "\n",
    "        for i in range(len(_index)):\n",
    "            j = _index[i]\n",
    "            _src_top_d_1.append([particle.dataframelize(j), top_1_daughter_idx_1[i], top_1_daughter_idx_2[i]])\n",
    "            _src_top_d_2.append([particle.dataframelize(j), top_2_daughter_idx_1[i], top_2_daughter_idx_2[i]])\n",
    "            _src_anti_top_d_1.append([particle.dataframelize(j), top_1_bar_daughter_idx_1[i], top_1_bar_daughter_idx_2[i]])\n",
    "            _src_anti_top_d_2.append([particle.dataframelize(j), top_2_bar_daughter_idx_1[i], top_2_bar_daughter_idx_2[i]])\n",
    "        with mp.Pool(PROCESS) as p:\n",
    "            _result_top_1 = p.starmap(quark_finder, _src_top_d_1)\n",
    "            p.close()\n",
    "            p.join()\n",
    "        print(\"Daughter of Top_1's daughter found.\") \n",
    "        with mp.Pool(PROCESS) as p:\n",
    "            _result_top_2 = p.starmap(quark_finder, _src_top_d_2)\n",
    "            p.close()\n",
    "            p.join()\n",
    "        print(\"Daughter of Top_2's daughter found.\") \n",
    "        with mp.Pool(PROCESS) as p:\n",
    "            _result_anti_top_1 = p.starmap(quark_finder, _src_anti_top_d_1)\n",
    "            p.close()\n",
    "            p.join()\n",
    "        print(\"Daughter of Anti-Top_1's daughter found.\") \n",
    "        with mp.Pool(PROCESS) as p:\n",
    "            _result_anti_top_2 = p.starmap(quark_finder, _src_anti_top_d_2)\n",
    "            p.close()\n",
    "            p.join()\n",
    "        print(\"Daughter of Anti-Top_2's daughter found.\") \n",
    "        for i in range(len(_index)):\n",
    "            parton_array[i][0], parton_array[i][1], parton_array[i][2] = _result_top_1[i][0], _result_top_1[i][1], _result_top_1[i][2]\n",
    "            parton_array[i][3], parton_array[i][4], parton_array[i][5] = _result_top_2[i][0], _result_top_2[i][1], _result_top_2[i][2]\n",
    "            parton_array[i][6], parton_array[i][7], parton_array[i][8] = _result_anti_top_1[i][0], _result_anti_top_1[i][1], _result_anti_top_1[i][2]\n",
    "            parton_array[i][9], parton_array[i][10], parton_array[i][11] = _result_anti_top_2[i][0], _result_anti_top_2[i][1], _result_anti_top_2[i][2]\n",
    "        print(\"+------------------------------------------------------------------------------------------------------+\")\n",
    "        print(\"Parton tracing section complete. The daughter of W+/W- and bbbar has been found. Cost: {0:.1f} s\".format(time.time()-start))\n",
    "        print(\"+------------------------------------------------------------------------------------------------------+\")\n",
    "    else :\n",
    "        print(\"Please select a correct model.\")\n",
    "\n",
    "    print(\"+------------------------------------------------------------------------------------------------------+\")\n",
    "    print(\"Recording the kinematics variables of partons in the selected event.\")\n",
    "    print(\"+------------------------------------------------------------------------------------------------------+\")\n",
    "    parton_pdgid = np.zeros((len(passed), NUM_OF_DAUGHTER))\n",
    "    parton_barcode = np.zeros((len(passed), NUM_OF_DAUGHTER))\n",
    "    parton_pt = np.zeros((len(passed), NUM_OF_DAUGHTER))\n",
    "    parton_eta = np.zeros((len(passed), NUM_OF_DAUGHTER))\n",
    "    parton_phi = np.zeros((len(passed), NUM_OF_DAUGHTER))\n",
    "    parton_mass = np.zeros((len(passed), NUM_OF_DAUGHTER))\n",
    "\n",
    "    for i in range(len(passed)):\n",
    "        idx = passed[i]\n",
    "        for j in range(NUM_OF_DAUGHTER):\n",
    "            dataset = particle.dataframelize(idx)\n",
    "            parton_pdgid[i][j] = dataset.iloc[int(parton_array[i][j]), 6]\n",
    "            parton_barcode[i][j] = barcode[j]\n",
    "            parton_pt[i][j] = dataset.iloc[int(parton_array[i][j]), 7]\n",
    "            parton_eta[i][j] = dataset.iloc[int(parton_array[i][j]), 8]\n",
    "            parton_phi[i][j] = dataset.iloc[int(parton_array[i][j]), 9]\n",
    "            parton_mass[i][j] = dataset.iloc[int(parton_array[i][j]), 10]\n",
    "\n",
    "\n",
    "    \n",
    "parse(INPUT_FILE, OUTPUT_FILE, MODLE, SINGLE, PROCESS, GENERATOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1 2 3]\n [2 3 4]\n [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "a = [[1,2,3], [1,2,3], [1,2,3]]\n",
    "b = [[2,3,4], [2,3,4], [2,3,4]]\n",
    "c = [4,5,6]\n",
    "\n",
    "a[0,:2] = b[0,:2]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([7, 8, 6, ..., 6, 6, 6])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "(jet.pt >= 25).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "btag_passed = np.where(((jet.btag == 1) & (jet.pt >=25) & (np.abs(jet.eta) < 2.5) ).sum() >= 2)\n",
    "non_btag_passed = np.where(((jet.pt >=25) & (np.abs(jet.eta) < 2.5) ).sum() >= 6)\n",
    "passed = np.intersect1d(btag_passed[0], non_btag_passed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(38875,)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "non_btag_passed[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([    0,     1,     2, ..., 99995, 99996, 99999]),)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "non_btag_passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(18312,)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "passed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  1%|          | 1044/100000 [00:00<00:09, 10436.35it/s]MODE: ttbar, len of pt: 100000\n",
      "Start jet marking.\n",
      "100%|██████████| 100000/100000 [00:09<00:00, 10448.73it/s]\n",
      " 28%|██▊       | 27540/100000 [00:00<00:00, 137960.74it/s]Start event marking.\n",
      "100%|██████████| 100000/100000 [00:00<00:00, 137014.62it/s]\n"
     ]
    }
   ],
   "source": [
    "MODEL = 'ttbar'\n",
    "marker_event, marker_jet, marker_btag = event_selection(jet.pt, jet.eta, jet.phi, jet.btag, tmp_lepton_pt, tmp_lepton_eta, tmp_lepton_phi, MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "18312"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "(marker_event == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "np.where((np.where(marker_event ==1) == passed ) == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([  0,   1,  10,  14,  16,  25,  27,  37,  38,  39,  41,  46,  51,\n",
       "        57,  60,  71,  72,  95, 100, 101])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "passed[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}