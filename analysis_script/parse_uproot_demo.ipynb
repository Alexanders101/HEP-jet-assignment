{
 "cells": [
  {
   "source": [
    "# HEP Jet assignment project - Data analysis and particle finding script"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Import essential packages.\n",
    "---\n",
    "* We will use [uproot](https://github.com/scikit-hep/uproot) packages to parse our .root file.\n",
    "* The content of function `particle properties` and `jet properties` is defined in `particle_properties.py` and `jet_properties.py`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from particle_properties_uproot import particle_properties  #import particle properties helper function from particle_properties.py\n",
    "from jet_properties_uproot import jet_properties  #import jet properties helper function from jet_properties.py\n",
    "import h5py"
   ]
  },
  {
   "source": [
    "## Loading data, determine parameters, and assign variable\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "data  = uproot.open('./tag_1_delphes_events.root')['Delphes']\n",
    "#data.show()\n",
    "\n",
    "particle = particle_properties(data)\n",
    "jet = jet_properties(data)\n",
    "\n",
    "Length = len(particle.event)\n",
    "test_length = 10\n",
    "\n",
    "PID_W_plus = 24 \n",
    "PID_W_minus = -24\n",
    "PID_DOWN = 1\n",
    "PID_DOWN_VAR = -1\n",
    "PID_UP = 2\n",
    "PID_UP_BAR = -2\n",
    "PID_STRANGE = 3\n",
    "PID_STRANGE_BAR = -3\n",
    "PID_CHARM = 4\n",
    "PID_CHARM_BAR = -4\n",
    "PID_BOTTOM = 5\n",
    "PID_BOTTOM_BAR = -5\n",
    "PID_TOP = 6\n",
    "PID_TOP_BAR = -6\n",
    "\n",
    "top_idx = np.zeros(len(particle.event))\n",
    "top_daughter_idx_1 = np.zeros(len(particle.event))\n",
    "top_daughter_pid_1 = np.zeros(len(particle.event))\n",
    "top_daughter_idx_2 = np.zeros(len(particle.event))\n",
    "top_daughter_pid_2 = np.zeros(len(particle.event))\n",
    "\n",
    "top_bar_idx = np.zeros(len(particle.event))\n",
    "top_bar_daughter_idx_1 = np.zeros(len(particle.event))\n",
    "top_bar_daughter_pid_1 = np.zeros(len(particle.event))\n",
    "top_bar_daughter_idx_2 = np.zeros(len(particle.event))\n",
    "top_bar_daughter_pid_2 = np.zeros(len(particle.event))\n",
    "\n",
    "parton_array = np.zeros([ len(particle.event) , 6, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(10000, 6, 7)"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "parton_array.shape"
   ]
  },
  {
   "source": [
    "## Event selection \n",
    "---\n",
    "1. Must contain:\n",
    "    * At least 2 b tagged jet.\n",
    "    * At least 6 jet exists.\n",
    "    * For each jet, require |$\\eta$| < 2.4 and $P_{T}$ > 20GeV. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n(10,) (10,)\n/usr/local/lib64/python3.6/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n  return array(a, dtype, copy=False, order=order, subok=True)\n"
    }
   ],
   "source": [
    "#Generate maker for each stage(event selection and jet selection.)\n",
    "marker_event = []\n",
    "marker_jet = []\n",
    "\n",
    "for i in range(test_length):\n",
    "    marker_event.append(0)\n",
    "    marker_jet.append(np.zeros([len(jet.pt[i])]))\n",
    "\n",
    "\n",
    "marker_event = np.asanyarray(marker_event)\n",
    "marker_jet = np.asanyarray(marker_jet)\n",
    "\n",
    "print(type(marker_event), type(marker_jet))\n",
    "print(marker_event.shape, marker_jet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+-----------------------------------------------------------------------------------------------------+\nStart event selection.\nEvent selection doen.\n+-----------------------------------------------------------------------------------------------------+\n+-----------------------------------------------------------------------------------------------------+\nStart jet selection.\nJet selection doen.\n+-----------------------------------------------------------------------------------------------------+\n"
    }
   ],
   "source": [
    "#Mark which event pass the selection\n",
    "print(\"+-----------------------------------------------------------------------------------------------------+\")\n",
    "print(\"Start event selection.\")\n",
    "for i in range(test_length):\n",
    "    min_pt = np.min(jet.pt[i])\n",
    "    num_of_eta_in_range = np.sum(jet.eta[i] < 2.4 ) \n",
    "    num_of_jet = len(jet.pt[i])\n",
    "    num_of_btagged = np.sum(jet.btag[i] == 1)\n",
    "    if min_pt > 20 and num_of_eta_in_range >= 6 and num_of_jet >=6 and num_of_btagged >= 2: \n",
    "        marker_event[i] = 1\n",
    "    else :\n",
    "        pass\n",
    "print(\"Event selection doen.\")\n",
    "print(\"+-----------------------------------------------------------------------------------------------------+\")\n",
    "\n",
    "#Mark which jet in each event pass the selection.\n",
    "print(\"+-----------------------------------------------------------------------------------------------------+\")\n",
    "print(\"Start jet selection.\")\n",
    "for i in range(test_length):\n",
    "    if marker_event[i] == 1:\n",
    "        for j in range(len(jet.pt[i])):\n",
    "            if jet.btag[i][j] == 1 and jet.pt[i][j] > 20 and jet.eta[i][j] < 2.4:\n",
    "                marker_jet[i][j] = 1 \n",
    "            elif jet.pt[i][j] > 20 and jet.eta[i][j] <= 2.4:\n",
    "                marker_jet[i][j] = 1\n",
    "            else :\n",
    "                pass\n",
    "        else :\n",
    "            pass \n",
    "print(\"Jet selection doen.\")\n",
    "print(\"+-----------------------------------------------------------------------------------------------------+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([202.87782 , 111.182884,  77.746796,  68.256065,  48.66473 ,\n        46.90613 ,  42.892666], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "jet.pt[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0, 1, 0, 0, 0, 0, 1], dtype=uint32)"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "jet.btag[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([-1.8974439 , -0.15003848, -0.41152957,  0.47566915, -1.3828474 ,\n       -0.57139546,  0.9232371 ], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "jet.eta[8]"
   ]
  },
  {
   "source": [
    "## Particle tracing and daughter finding section\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_particle_tracing(dataset, PID_d, idx):\n",
    "    if (dataset.iloc[idx,6] == PID_d):\n",
    "        return dataset.iloc[idx,4]\n",
    "\n",
    "def particle_tracing(dataset, PID, STATUS):\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        if(dataset.iloc[i,1] == STATUS and dataset.iloc[i,6] == PID ): \n",
    "            daughter_index = int(dataset.iloc[i,0])\n",
    "    if( dataset.iloc[daughter_index,6] == PID ):\n",
    "        shifted_particle_index = dataset.iloc[daughter_index, 4]\n",
    "\n",
    "\n",
    "    while dataset.iloc[shifted_particle_index,6] == PID:\n",
    "            init_shifted_particle_index = shifted_particle_index\n",
    "            shifted_particle_index = shift_particle_tracing(dataset, PID, init_shifted_particle_index)       \n",
    "\n",
    "    dauthter_idx_1 = dataset.iloc[init_shifted_particle_index, 4]\n",
    "    daughter_pid_1 = dataset.iloc[dauthter_idx_1, 6]\n",
    "\n",
    "    dauthter_idx_2 = dataset.iloc[init_shifted_particle_index, 5]\n",
    "    daughter_pid_2 = dataset.iloc[dauthter_idx_2, 6]\n",
    "\n",
    "    return init_shifted_particle_index, dauthter_idx_1, daughter_pid_1, dauthter_idx_2, daughter_pid_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+------------------------------------------------------------------------------------------------------+\nStart parsing event : 0\nStart to trace top quark and find its daughters.\n+------------------------------------------------------~-----------------------------------------------+\nStart to find top_bar quark and its daughters.\n+------------------------------------------------------------------------------------------------------+\n+------------------------------------------------------------------------------------------------------+\nStart parsing event : 1\nStart to trace top quark and find its daughters.\n+------------------------------------------------------~-----------------------------------------------+\nStart to find top_bar quark and its daughters.\n+------------------------------------------------------------------------------------------------------+\n+------------------------------------------------------------------------------------------------------+\nStart parsing event : 2\nStart to trace top quark and find its daughters.\n+------------------------------------------------------~-----------------------------------------------+\nStart to find top_bar quark and its daughters.\n+------------------------------------------------------------------------------------------------------+\n+------------------------------------------------------------------------------------------------------+\nStart parsing event : 3\nStart to trace top quark and find its daughters.\n+------------------------------------------------------~-----------------------------------------------+\nStart to find top_bar quark and its daughters.\n+------------------------------------------------------------------------------------------------------+\n+------------------------------------------------------------------------------------------------------+\nStart parsing event : 4\nStart to trace top quark and find its daughters.\n+------------------------------------------------------~-----------------------------------------------+\nStart to find top_bar quark and its daughters.\n+------------------------------------------------------------------------------------------------------+\n+------------------------------------------------------------------------------------------------------+\nStart parsing event : 5\nStart to trace top quark and find its daughters.\n+------------------------------------------------------~-----------------------------------------------+\nStart to find top_bar quark and its daughters.\n+------------------------------------------------------------------------------------------------------+\n+------------------------------------------------------------------------------------------------------+\nStart parsing event : 6\nStart to trace top quark and find its daughters.\n+------------------------------------------------------~-----------------------------------------------+\nStart to find top_bar quark and its daughters.\n+------------------------------------------------------------------------------------------------------+\n+------------------------------------------------------------------------------------------------------+\nStart parsing event : 7\nStart to trace top quark and find its daughters.\n+------------------------------------------------------~-----------------------------------------------+\nStart to find top_bar quark and its daughters.\n+------------------------------------------------------------------------------------------------------+\n+------------------------------------------------------------------------------------------------------+\nStart parsing event : 8\nStart to trace top quark and find its daughters.\n+------------------------------------------------------~-----------------------------------------------+\nStart to find top_bar quark and its daughters.\n+------------------------------------------------------------------------------------------------------+\n+------------------------------------------------------------------------------------------------------+\nStart parsing event : 9\nStart to trace top quark and find its daughters.\n+------------------------------------------------------~-----------------------------------------------+\nStart to find top_bar quark and its daughters.\n+------------------------------------------------------------------------------------------------------+\n"
    }
   ],
   "source": [
    "for i in range(test_length):\n",
    "    print(\"+------------------------------------------------------------------------------------------------------+\")\n",
    "    print(\"Start parsing event : {0}\\nStart to trace top quark and find its daughters.\".format(i))\n",
    "    top_idx[i], top_daughter_idx_1[i], top_daughter_pid_1[i], top_daughter_idx_2[i], top_daughter_pid_2[i] = particle_tracing(particle.dataframelize(i), PID_TOP, 22)\n",
    "    print(\"+------------------------------------------------------~-----------------------------------------------+\")\n",
    "    print(\"Start to find top_bar quark and its daughters.\")\n",
    "    top_bar_idx[i], top_bar_daughter_idx_1[i], top_bar_daughter_pid_1[i], top_bar_daughter_idx_2[i], top_bar_daughter_pid_2[i] = particle_tracing(particle.dataframelize(i), PID_TOP_BAR, 22)\n",
    "    print(\"+------------------------------------------------------------------------------------------------------+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tracing the daughter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input two daughter of top/top_bar and find their daughter\n",
    "def quark_finder(dataset, mother_idx_1, mother_idx_2):\n",
    "    \n",
    "    #Specific two daughter of top\n",
    "    def W_b_specifier(dataset, input_1_idx, input_2_idx):\n",
    "        if dataset.iloc[int(input_1_idx),6] == PID_W_plus or dataset.iloc[int(input_1_idx),6] == PID_W_minus :\n",
    "            return int(input_1_idx), int(dataset.iloc[int(input_1_idx),6]), int(input_2_idx)\n",
    "        elif dataset.iloc[int(input_1_idx),6] == PID_BOTTOM or dataset.iloc[int(input_1_idx),6] == PID_BOTTOM_BAR :\n",
    "            return  int(input_2_idx), int(dataset.iloc[int(input_1_idx),6]), int(input_1_idx)\n",
    "        else :\n",
    "            print(\"Please check your data.\")\n",
    "    \n",
    "    W_boson_idx, mother_pid, b_quark_idx = W_b_specifier(dataset, mother_idx_1, mother_idx_2)\n",
    "    \n",
    "    #Find the two daughters of boson\n",
    "    \n",
    "    daughter_1_idx = dataset.iloc[W_boson_idx, 4]\n",
    "    daughter_1_pid = dataset.iloc[daughter_1_idx, 6]\n",
    "    daughter_2_idx = dataset.iloc[W_boson_idx, 5]\n",
    "    daughter_2_pid = dataset.iloc[daughter_2_idx, 6]\n",
    "\n",
    "    \n",
    "    if daughter_1_pid == mother_pid or daughter_2_pid == mother_pid:\n",
    "\n",
    "        init_idx = W_boson_idx\n",
    "        daughter_pid = daughter_1_pid\n",
    "        if daughter_2_pid == mother_pid:\n",
    "            daughter_pid = daughter_2_pid\n",
    "        while daughter_pid == mother_pid :\n",
    "            daughter_1_idx = dataset.iloc[int(init_idx), 4]\n",
    "            daughter_2_idx = dataset.iloc[int(init_idx), 5]\n",
    "\n",
    "            daughter_1_pid = dataset.iloc[int(daughter_1_idx), 6]\n",
    "            daughter_2_pid = dataset.iloc[int(daughter_2_idx), 6]\n",
    "\n",
    "            daughter_pid = daughter_1_pid\n",
    "            init_idx = daughter_1_idx\n",
    "            if daughter_2_pid == mother_pid:\n",
    "                daughter_pid = daughter_2_pid\n",
    "                init_idx = daughter_2_idx\n",
    "            \n",
    "            \n",
    "            print(\"Temporary daughter 1 indxe: {0}, PID: {1}\".format(daughter_1_idx, daughter_1_pid))\n",
    "            print(\"Temporary daughter 2 indxe: {0}, PID: {1}\".format(daughter_2_idx, daughter_2_pid))\n",
    "\n",
    "    \n",
    "    print(\"Found daughter 1 index: {0}, PID: {1}.\\nFound daughter 2 index: {2}, PID: {3}\".format(daughter_1_idx, daughter_1_pid, daughter_2_idx, daughter_2_pid))\n",
    "    return  b_quark_idx, daughter_1_idx, daughter_2_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+------------------------------------------------------------------------------------------------------+\nStart parsing event : 8\nStart to find top quark's daughters.\nTemporary daughter 1 indxe: 407, PID: 24\nTemporary daughter 2 indxe: 407, PID: 24\nTemporary daughter 1 indxe: 446, PID: 4\nTemporary daughter 2 indxe: 447, PID: -3\nFound daughter 1 index: 446, PID: 4.\nFound daughter 2 index: 447, PID: -3\n+------------------------------------------------------~-----------------------------------------------+\nStart to find top_bar quark's daughters.\nTemporary daughter 1 indxe: 360, PID: -24\nTemporary daughter 2 indxe: 360, PID: -24\nTemporary daughter 1 indxe: 400, PID: -24\nTemporary daughter 2 indxe: 401, PID: 22\nTemporary daughter 1 indxe: 414, PID: 1\nTemporary daughter 2 indxe: 415, PID: -2\nFound daughter 1 index: 414, PID: 1.\nFound daughter 2 index: 415, PID: -2\n+------------------------------------------------------------------------------------------------------+\n"
    }
   ],
   "source": [
    "for i in range(test_length):\n",
    "    if marker_event[i] == 1 :\n",
    "        print(\"+------------------------------------------------------------------------------------------------------+\")\n",
    "        print(\"Start parsing event : {0}\\nStart to find top quark's daughters.\".format(i))\n",
    "        parton_array[i][0][0], parton_array[i][1][0], parton_array[i][2][0] = quark_finder(particle.dataframelize(i), top_daughter_idx_1[i], top_daughter_idx_2[i])\n",
    "        print(\"+------------------------------------------------------~-----------------------------------------------+\")\n",
    "        print(\"Start to find top_bar quark's daughters.\")\n",
    "        parton_array[i][3][0], parton_array[i][4][0], parton_array[i][5][0], = quark_finder(particle.dataframelize(i), top_bar_daughter_idx_1[i], top_bar_daughter_idx_2[i])\n",
    "        print(\"+------------------------------------------------------------------------------------------------------+\")\n",
    "    elif marker_event[i] == 0 :\n",
    "        parton_array[i] = 'Nan'\n",
    "    else: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode = np.array([34, 40, 40, 17, 20, 20])\n",
    "for i in range(test_length):\n",
    "    if marker_event[i] == 1:\n",
    "        for j in range(0,6):\n",
    "            dataset = particle.dataframelize(i)\n",
    "            parton_array[i][j][1] = dataset.iloc[int(parton_array[i][j][0]), 6]  #PDGID\n",
    "            parton_array[i][j][2] = barcode[j]\n",
    "            parton_array[i][j][3] = dataset.iloc[int(parton_array[i][j][0]), 7]  #Pt\n",
    "            parton_array[i][j][4] = dataset.iloc[int(parton_array[i][j][0]), 8]  #Eta\n",
    "            parton_array[i][j][5] = dataset.iloc[int(parton_array[i][j][0]), 9]  #Phi\n",
    "            parton_array[i][j][6] = dataset.iloc[int(parton_array[i][j][0]), 10]  #Mass"
   ]
  },
  {
   "source": [
    "## Parton-jet matching section\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Define the function for computing delta_R\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deltaPhi(phi1,phi2):\n",
    "    phi = phi1-phi2\n",
    "    while phi >= np.pi: phi -= np.pi*2.\n",
    "    while phi < -np.pi: phi += np.pi*2.\n",
    "    return phi\n",
    "\n",
    "def delta_R(eta1, phi1, eta2, phi2):\n",
    "    return np.sqrt(deltaPhi(phi1,phi2)**2+(eta1-eta2)**2)\n",
    "\n",
    "def min_delta_R(target_1, target_2):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "/usr/local/lib64/python3.6/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n  return array(a, dtype, copy=False, order=order, subok=True)\n"
    }
   ],
   "source": [
    "dR_between_parton_jet = []\n",
    "dR_between_parton_parton = []\n",
    "\n",
    "for i in range(test_length):\n",
    "    dR_between_parton_jet.append(np.zeros([len(jet.pt[i]) * 6])) # # of connection = num of jet * num of parton\n",
    "    dR_between_parton_parton.append(np.zeros([15])) # C^{6}_{2} = 15\n",
    "\n",
    "dR_between_parton_jet = np.asanyarray(dR_between_parton_jet)\n",
    "dR_between_parton_parton = np.asanyarray(dR_between_parton_parton)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "7\n/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n  from ipykernel import kernelapp as app\n"
    }
   ],
   "source": [
    "max_num_of_jet_cand = []\n",
    "for i in range(test_length):\n",
    "    max_num_of_jet_cand.append(len(jet.pt[i]))\n",
    "max_num_of_jet_cand = np.asanyarray(max_num_of_jet_cand)\n",
    "max_num_of_jet = max_num_of_jet_cand.max()\n",
    "print(max_num_of_jet)\n",
    "\n",
    "#parton_jet_matching = np.zeros([len(jet.event), 6, 2])\n",
    "matching_jet = []\n",
    "matching_parton = []\n",
    "for i in range(test_length):\n",
    "    matching_jet.append(np.zeros([len(jet.pt[i])]))\n",
    "    matching_parton.append(np.zeros([6]))\n",
    "\n",
    "matching_jet = np.array(matching_jet)\n",
    "matching_parton = np.array(matching_parton)"
   ]
  },
  {
   "source": [
    "### Computing delta_R between each parton and jet"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "8 0 0\n4.165814946462408\n8 0 1\n1.2409081541734457\n8 0 2\n1.4370510145964808\n8 0 3\n2.1470968766152545\n8 0 4\n2.393077086271537\n8 0 5\n2.1879551259629246\n8 0 6\n0.0561078375283632\n8 1 0\n2.6256207464651395\n8 1 1\n2.782948879409113\n8 1 2\n2.0264794615009776\n8 1 3\n0.09987564369420499\n8 1 4\n3.198124238125701\n8 1 5\n1.2434733652084748\n8 1 6\n2.2458551402310434\n8 2 0\n2.2180904523490477\n8 2 1\n2.093791106499452\n8 2 2\n1.1726524584815639\n8 2 3\n1.119654032421636\n8 2 4\n2.1354500845397135\n8 2 5\n0.06924021520448215\n8 2 6\n2.114348183694153\n8 3 0\n3.0131561260149633\n8 3 1\n0.04618709568092776\n8 3 2\n0.9781131015131724\n8 3 3\n2.7257403402641316\n8 3 4\n1.2511927750734346\n8 3 5\n2.156586918524361\n8 3 6\n1.1983259775432709\n8 4 0\n3.290976975662634\n8 4 1\n0.8996986696106917\n8 4 2\n0.04477846088242515\n8 4 3\n1.9338889257771585\n8 4 4\n1.2595089340050385\n8 4 5\n1.2126670425520003\n8 4 6\n1.348026118591255\n8 5 0\n2.689800322739739\n8 5 1\n1.220875738857931\n8 5 2\n1.213521612950747\n8 5 3\n3.0773905519315004\n8 5 4\n0.030359442648677255\n8 5 5\n2.0828738870521257\n8 5 6\n2.3143107331126758\n"
    }
   ],
   "source": [
    "for i in range(test_length):\n",
    "    if marker_event[i] == 1:\n",
    "        j = 0\n",
    "        a = 0\n",
    "        b = 0\n",
    "        while a < 6 :\n",
    "            for b in range( len(jet.pt[i]) ):\n",
    "                print(i, a, b)\n",
    "                print(delta_R( parton_array[i][a][4], parton_array[i][a][5], jet.eta[i][b], jet.phi[i][b]))\n",
    "                dR_between_parton_jet[i][j] = delta_R( parton_array[i][a][4], parton_array[i][a][5], jet.eta[i][b], jet.phi[i][b])\n",
    "                j +=1\n",
    "            a += 1 \n",
    "    else :\n",
    "        dR_between_parton_jet[i] = 'Nan'\n",
    "        \n",
    "        "
   ]
  },
  {
   "source": [
    "### Matching jet and parton by finding the Min(dR(parton, jet))"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+------------------------------------------------------------------------------------------------------+\n(6, 7)\n          0         1         2         3         4         5\n0  4.165815  2.625621  2.218090  3.013156  3.290977  2.689800\n1  1.240908  2.782949  2.093791  0.046187  0.899699  1.220876\n2  1.437051  2.026479  1.172652  0.978113  0.044778  1.213522\n3  2.147097  0.099876  1.119654  2.725740  1.933889  3.077391\n4  2.393077  3.198124  2.135450  1.251193  1.259509  0.030359\n5  2.187955  1.243473  0.069240  2.156587  1.212667  2.082874\n6  0.056108  2.245855  2.114348  1.198326  1.348026  2.314311\n+------------------------------------------------------------------------------------------------------+\nMin val: 0.030359442648677255\nThe position of minimun appears. Raw: 4, Colume: 5\nThe dataset after delete the minimun's raw and colume:\n          0         1         2         3         4\n0  4.165815  2.625621  2.218090  3.013156  3.290977\n1  1.240908  2.782949  2.093791  0.046187  0.899699\n2  1.437051  2.026479  1.172652  0.978113  0.044778\n3  2.147097  0.099876  1.119654  2.725740  1.933889\n5  2.187955  1.243473  0.069240  2.156587  1.212667\n6  0.056108  2.245855  2.114348  1.198326  1.348026\n+------------------------------------------------------------------------------------------------------+\nMin val: 0.04477846088242515\nThe position of minimun appears. Raw: 2, Colume: 4\nThe dataset after delete the minimun's raw and colume:\n          0         1         2         3\n0  4.165815  2.625621  2.218090  3.013156\n1  1.240908  2.782949  2.093791  0.046187\n3  2.147097  0.099876  1.119654  2.725740\n5  2.187955  1.243473  0.069240  2.156587\n6  0.056108  2.245855  2.114348  1.198326\n+------------------------------------------------------------------------------------------------------+\nMin val: 0.04618709568092776\nThe position of minimun appears. Raw: 1, Colume: 3\nThe dataset after delete the minimun's raw and colume:\n          0         1         2\n0  4.165815  2.625621  2.218090\n3  2.147097  0.099876  1.119654\n5  2.187955  1.243473  0.069240\n6  0.056108  2.245855  2.114348\n+------------------------------------------------------------------------------------------------------+\nMin val: 0.0561078375283632\nThe position of minimun appears. Raw: 6, Colume: 0\nThe dataset after delete the minimun's raw and colume:\n          1         2\n0  2.625621  2.218090\n3  0.099876  1.119654\n5  1.243473  0.069240\n+------------------------------------------------------------------------------------------------------+\nMin val: 0.06924021520448215\nThe position of minimun appears. Raw: 5, Colume: 2\nThe dataset after delete the minimun's raw and colume:\n          1\n0  2.625621\n3  0.099876\n+------------------------------------------------------------------------------------------------------+\nMin val: 0.09987564369420499\nThe position of minimun appears. Raw: 3, Colume: 1\nThe dataset after delete the minimun's raw and colume:\nEmpty DataFrame\nColumns: []\nIndex: [0]\n"
    }
   ],
   "source": [
    "for i in range(test_length):\n",
    "    if marker_event[i] == 1:\n",
    "        print(\"+------------------------------------------------------------------------------------------------------+\")\n",
    "        # print(dR_between_parton_jet.shape)\n",
    "        array = np.reshape(dR_between_parton_jet[i], [6, len(jet.pt[i])])\n",
    "        print(array.shape)\n",
    "        \n",
    "        dataset = pd.DataFrame({'0': array[0,:], \n",
    "                                '1': array[1,:],\n",
    "                                '2': array[2,:],\n",
    "                                '3': array[3,:],\n",
    "                                '4': array[4,:],\n",
    "                                '5': array[5,:],\n",
    "                                })\n",
    "        print(dataset)\n",
    "\n",
    "        for j in range(0,6):\n",
    "            print(\"+------------------------------------------------------------------------------------------------------+\")\n",
    "            min_val = dataset.stack().min()\n",
    "            if min_val < 0.4:\n",
    "                print(\"Min val: {0}\".format(min_val))\n",
    "                min_idx, min_col = dataset.stack().idxmin()\n",
    "                matching_parton[i][j] = int(min_idx)\n",
    "                matching_jet[i][j] = int(min_col)\n",
    "                #parton_jet_matching[i][j][0] = int(min_idx)\n",
    "                #parton_jet_matching[i][j][1] = int(min_col)\n",
    "                print(\"The position of minimun appears. Raw: {0}, Colume: {1}\".format(min_idx, min_col))\n",
    "                dataset = dataset.drop([min_col], axis=1)\n",
    "                dataset = dataset.drop([min_idx], axis=0)\n",
    "                print(\"The dataset after delete the minimun's raw and colume:\")\n",
    "                print(dataset)\n",
    "            else:\n",
    "                matching_parton[i][j] = 'Nan'\n",
    "                matching_jet[i][j] = 'Nan'\n",
    "                #parton_jet_matching[i][j][0] = 'Nan'\n",
    "                #parton_jet_matching[i][j][1] = 'Nan'\n",
    "        for k in range(6, len(jet.pt[i])):\n",
    "            matching_jet[i][k] = 'Nan'\n",
    "    else : pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "parton_index = np.zeros([len(jet.event), 6])\n",
    "jet_index = []\n",
    "np.zeros([len(jet.event), 6])\n",
    "for i in range(test_length):\n",
    "    jet_index.append(np.zeros([len(jet.pt[i])]))\n",
    "\n",
    "\n",
    "for i in range(test_length):\n",
    "    if marker_event[i] == 1:\n",
    "        for j in range(0,6):\n",
    "            parton_index[i][j] = matching_parton[i][j]\n",
    "        for k in range(len(jet.pt[i])):\n",
    "            jet_index[i][k] = matching_jet[i][k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([4., 2., 1., 6., 5., 3.])"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "parton_index[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([ 5.,  4.,  3.,  0.,  2.,  1., nan])"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "jet_index[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n  \"\"\"\n"
    }
   ],
   "source": [
    "jet_barcode = []\n",
    "for i in range(test_length):\n",
    "    jet_barcode.append(np.zeros([len(jet.pt[i])]))\n",
    "\n",
    "jet_barcode = np.array(jet_barcode)\n",
    "\n",
    "for i in range(test_length):\n",
    "    if marker_event[i] == 1:\n",
    "        for j in range(len(jet_index[i])):\n",
    "            if jet_index[i][j] == 0:\n",
    "                jet_barcode[i][j] = barcode[0]\n",
    "            elif jet_index[i][j] == 1: \n",
    "                jet_barcode[i][j] = barcode[1]\n",
    "            elif jet_index[i][j] == 2: \n",
    "                jet_barcode[i][j] = barcode[2]\n",
    "            elif jet_index[i][j] == 3: \n",
    "                jet_barcode[i][j] = barcode[3]\n",
    "            elif jet_index[i][j] == 4: \n",
    "                jet_barcode[i][j] = barcode[4]\n",
    "            elif jet_index[i][j] == 5: \n",
    "                jet_barcode[i][j] = barcode[5]\n",
    "            else :\n",
    "                jet_barcode[i][j] = 'Nan'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([20., 20., 17., 34., 40., 40., nan])"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "jet_barcode[8]"
   ]
  },
  {
   "source": [
    "## Saved selected events\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Final jet selection (kick out the jet we don't want by the information of `marker_jet` array.)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n  \n/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n  from ipykernel import kernelapp as app\n/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n  app.launch_new_instance()\n/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
    }
   ],
   "source": [
    "jet_pt = []\n",
    "jet_eta = []\n",
    "jet_phi = []\n",
    "jet_btag = []\n",
    "jet_mass = []\n",
    "\n",
    "for i in range(test_length):\n",
    "    jet_pt.append(np.zeros([len(jet.pt[i])]))\n",
    "    jet_eta.append(np.zeros([len(jet.pt[i])]))\n",
    "    jet_phi.append(np.zeros([len(jet.pt[i])]))\n",
    "    jet_btag.append(np.zeros([len(jet.pt[i])]))\n",
    "    jet_mass.append(np.zeros([len(jet.pt[i])]))\n",
    "\n",
    "jet_pt = np.array(jet_pt)\n",
    "jet_eta = np.array(jet_eta)\n",
    "jet_phi = np.array(jet_phi)\n",
    "jet_btag = np.array(jet_btag)\n",
    "jet_mass = np.array(jet_mass)\n",
    "\n",
    "for i in range(test_length):\n",
    "    if marker_event[i] == 1:\n",
    "        for j in range(len(jet.pt[i])):\n",
    "            if marker_jet[i][j] == 1:\n",
    "                jet_pt[i][j] = jet.pt[i][j]\n",
    "                jet_eta[i][j] = jet.eta[i][j]\n",
    "                jet_phi[i][j] = jet.phi[i][j]\n",
    "                jet_btag[i][j] = jet.btag[i][j]\n",
    "                jet_mass[i][j] = jet.mass[i][j]\n",
    "            else :\n",
    "                jet_pt[i][j] = 'Nan'\n",
    "                jet_eta[i][j] = 'Nan'\n",
    "                jet_phi[i][j] = 'Nan'\n",
    "                jet_btag[i][j] = 'Nan'\n",
    "                jet_mass[i][j] = 'Nan'\n"
   ]
  },
  {
   "source": [
    "### Purge the event we don't want"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_jet_parton_index = []\n",
    "hdf5_jet_barcode = []\n",
    "hdf5_jet_pt = []\n",
    "hdf5_jet_eta = []\n",
    "hdf5_jet_phi = []\n",
    "hdf5_jet_mass = []\n",
    "hdf5_jet_btagged = []\n",
    "\n",
    "hdf5_parton_jet_index = []\n",
    "hdf5_parton_pdgid = []\n",
    "hdf5_parton_barcode = []\n",
    "hdf5_parton_pt = []\n",
    "hdf5_parton_eta = []\n",
    "hdf5_parton_phi = []\n",
    "hdf5_parton_mass = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(test_length):\n",
    "    if marker_event[i] == 1:\n",
    "        hdf5_jet_parton_index.append(parton_index[i])\n",
    "        hdf5_jet_barcode.append(jet_barcode[i])\n",
    "        hdf5_jet_pt.append(jet_pt[i])\n",
    "        hdf5_jet_eta.append(jet_eta[i])\n",
    "        hdf5_jet_phi.append(jet_phi[i])\n",
    "        hdf5_jet_mass.append(jet_mass[i])\n",
    "        hdf5_jet_btagged.append(jet_btag[i])\n",
    "    else: pass\n",
    "\n",
    "\n",
    "\n",
    "for i in range(test_length):\n",
    "    if marker_event[i] == 1:\n",
    "        parton_pdgid = []\n",
    "        parton_pt = []\n",
    "        parton_eta = []\n",
    "        parton_phi = []\n",
    "        parton_mass = []\n",
    "        for j in range(0,6):\n",
    "            parton_pdgid.append(parton_array[i][j][1])\n",
    "            parton_pt.append(parton_array[i][j][3])\n",
    "            parton_eta.append(parton_array[i][j][4])\n",
    "            parton_phi.append(parton_array[i][j][5])\n",
    "            parton_mass.append(parton_array[i][j][6])\n",
    "\n",
    "        hdf5_parton_jet_index.append(jet_index[i])\n",
    "        hdf5_parton_pdgid.append(parton_array[i])\n",
    "        hdf5_parton_barcode.append(barcode)\n",
    "        hdf5_parton_pt.append(parton_pt)\n",
    "        hdf5_parton_eta.append(parton_eta)\n",
    "        hdf5_parton_phi.append(parton_phi)\n",
    "        hdf5_parton_mass.append(parton_mass)      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_jet_parton_index = np.array(hdf5_jet_parton_index)\n",
    "hdf5_jet_barcode = np.array(hdf5_jet_barcode)\n",
    "hdf5_jet_pt = np.array(hdf5_jet_pt)\n",
    "hdf5_jet_eta = np.array(hdf5_jet_eta)\n",
    "hdf5_jet_phi = np.array(hdf5_jet_phi)\n",
    "hdf5_jet_mass = np.array(hdf5_jet_mass)\n",
    "hdf5_jet_btagged = np.array(hdf5_jet_btagged)\n",
    "\n",
    "hdf5_parton_jet_index = np.array(hdf5_parton_jet_index)\n",
    "hdf5_parton_pdgid = np.array(hdf5_parton_pdgid)\n",
    "hdf5_parton_barcode = np.array(hdf5_parton_barcode)\n",
    "hdf5_parton_pt = np.array(hdf5_parton_pt)\n",
    "hdf5_parton_eta = np.array(hdf5_parton_eta)\n",
    "hdf5_parton_phi = np.array(hdf5_parton_phi)\n",
    "hdf5_parton_mass = np.array(hdf5_parton_mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the event which pass the selection\n",
    "with h5py.File(\"event_record.h5\",'w') as f:\n",
    "    group_jet = f.create_group('jet')\n",
    "    group_jet['Parton_Index'] = hdf5_jet_parton_index\n",
    "    group_jet['Barcode'] = hdf5_jet_barcode\n",
    "    group_jet['Pt'] = hdf5_jet_pt\n",
    "    group_jet['Eta'] = hdf5_jet_eta\n",
    "    group_jet['Phi'] = hdf5_jet_phi\n",
    "    group_jet['Mass'] = hdf5_jet_mass\n",
    "    group_jet['BTag'] = hdf5_jet_btagged\n",
    "    \n",
    "    group_parton = f.create_group('parton')\n",
    "    group_parton['Jet_Index'] = hdf5_parton_jet_index\n",
    "    group_parton['Pdgid'] = hdf5_parton_pdgid\n",
    "    group_parton['Barcode'] = hdf5_parton_barcode\n",
    "    group_parton['Pt'] = hdf5_parton_pt\n",
    "    group_parton['Eta'] = hdf5_parton_eta\n",
    "    group_parton['Phi'] = hdf5_parton_phi\n",
    "    group_parton['Mass'] = hdf5_parton_mass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<KeysViewHDF5 ['jet', 'parton']>\n<HDF5 group \"/jet\" (7 members)> <HDF5 group \"/parton\" (7 members)>\n<KeysViewHDF5 ['BTag', 'Barcode', 'Eta', 'Mass', 'Parton_Index', 'Phi', 'Pt']> <KeysViewHDF5 ['Barcode', 'Eta', 'Jet_Index', 'Mass', 'Pdgid', 'Phi', 'Pt']>\n<class 'h5py._hl.dataset.Dataset'>\n<HDF5 dataset \"Parton_Index\": shape (1, 6), type \"<f8\">\n[4. 2. 1. 6. 5. 3.]\n[20. 20. 17. 34. 40. 40. nan]\n[202.87782288 111.18288422  77.74679565  68.25606537  48.66473007\n  46.90613174  42.89266586]\n"
    }
   ],
   "source": [
    "with h5py.File(\"event_record.h5\",'r') as f:\n",
    "    print(f.keys())\n",
    "    jet = f['jet']\n",
    "    parton = f['parton']\n",
    "    print(jet, parton)\n",
    "    print(jet.keys(), parton.keys())\n",
    "    print(type(jet['Parton_Index']))\n",
    "    print(jet['Parton_Index'])\n",
    "    for a in jet['Parton_Index']:\n",
    "        print(a)\n",
    "    for b in jet['Barcode']:\n",
    "        print(b)\n",
    "    for c in jet['Pt']:\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bite4e4b34d0f48422d8a0b164df5226f44"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}